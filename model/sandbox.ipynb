{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from segnet import segnet\n",
    "from generator import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "nv=int(2**16) # variants\n",
    "na=2          # alleles\n",
    "nc=7          # ancestry classes\n",
    "ne=100        # number of epochs\n",
    "gen=True      # use data generator\n",
    "hor=False     # use multi-gpu\n",
    "oce=True      # include oceanian samples\n",
    "dev=False     # do we have a dev set\n",
    "\n",
    "# reproducibility\n",
    "# np.random.seed(23910464)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure horovod if we're using multiple gpus\n",
    "# - note that this doesn't work within a jupyter notebook\n",
    "# - but you can use it to assign one of the two gpus to the tf instance\n",
    "# - ((probably))\n",
    "if hor: \n",
    "    import horovod.keras as hvd \n",
    "\n",
    "    # initialize horovod instance -- this currently only works on galangal\n",
    "    hvd.init()\n",
    "\n",
    "    # assign GPUs to horovod \n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    if gpus:\n",
    "        # tf.config in tf <= 1.6\n",
    "        tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], 'GPU')\n",
    "    print(gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check that we're on gpu -- use #1\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"segnet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 65536, 2)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 65536, 2)     0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_down1 (Conv1D)            (None, 65536, 8)     264         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 65536, 8)     0           conv1_down1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 65536, 8)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1_down2 (Conv1D)            (None, 65536, 8)     1032        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 65536, 8)     0           conv1_down2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 65536, 8)     0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool0 (MaxPooling1D)            (None, 16384, 8)     0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_down1 (Conv1D)            (None, 16384, 16)    2064        pool0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 16384, 16)    0           conv2_down1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 16384, 16)    0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_down2 (Conv1D)            (None, 16384, 16)    4112        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16384, 16)    0           conv2_down2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16384, 16)    0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling1D)            (None, 4096, 16)     0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3_down1 (Conv1D)            (None, 4096, 32)     8224        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 4096, 32)     0           conv3_down1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 4096, 32)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_down2 (Conv1D)            (None, 4096, 32)     16416       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 4096, 32)     0           conv3_down2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 4096, 32)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (MaxPooling1D)            (None, 1024, 32)     0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_down1 (Conv1D)            (None, 1024, 64)     32832       pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 1024, 64)     0           conv4_down1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 1024, 64)     0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv4_down2 (Conv1D)            (None, 1024, 64)     65600       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 1024, 64)     0           conv4_down2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 1024, 64)     0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling1D)            (None, 256, 64)      0           dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv5_down1 (Conv1D)            (None, 256, 128)     131200      pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 256, 128)     0           conv5_down1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 256, 128)     0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv5_down2 (Conv1D)            (None, 256, 128)     262272      dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 256, 128)     0           conv5_down2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 256, 128)     0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "pool4 (MaxPooling1D)            (None, 64, 128)      0           dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 256)      0           pool4[0][0]                      \n",
      "                                                                 pool4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up4 (UpSampling1D)              (None, 256, 256)     0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_up0 (Conv1D)              (None, 256, 128)     524416      up4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 256, 128)     0           conv4_up0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 256, 128)     0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_up1 (Conv1D)              (None, 256, 128)     262272      dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 256, 128)     0           conv4_up1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 256, 128)     0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256, 192)     0           pool3[0][0]                      \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up3 (UpSampling1D)              (None, 1024, 192)    0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_up0 (Conv1D)              (None, 1024, 64)     196672      up3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 1024, 64)     0           conv3_up0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 1024, 64)     0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_up1 (Conv1D)              (None, 1024, 64)     65600       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 1024, 64)     0           conv3_up1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 1024, 64)     0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1024, 96)     0           pool2[0][0]                      \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up2 (UpSampling1D)              (None, 4096, 96)     0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2_up0 (Conv1D)              (None, 4096, 32)     49184       up2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 4096, 32)     0           conv2_up0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 4096, 32)     0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2_up1 (Conv1D)              (None, 4096, 32)     16416       dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 4096, 32)     0           conv2_up1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 4096, 32)     0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 4096, 48)     0           pool1[0][0]                      \n",
      "                                                                 dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up1 (UpSampling1D)              (None, 16384, 48)    0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1_up0 (Conv1D)              (None, 16384, 16)    12304       up1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16384, 16)    0           conv1_up0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 16384, 16)    0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1_up1 (Conv1D)              (None, 16384, 16)    4112        dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16384, 16)    0           conv1_up1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 16384, 16)    0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 16384, 24)    0           pool0[0][0]                      \n",
      "                                                                 dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up0 (UpSampling1D)              (None, 65536, 24)    0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv0_up0 (Conv1D)              (None, 65536, 8)     3080        up0[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 65536, 8)     0           conv0_up0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 65536, 8)     0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv0_up1 (Conv1D)              (None, 65536, 8)     1032        dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 65536, 8)     0           conv0_up1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 65536, 8)     0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 65536, 7)     63          dropout_21[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,659,167\n",
      "Trainable params: 1,659,167\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# declare model\n",
    "model=segnet(input_shape=(nv, na), n_classes=nc-1+int(oce), n_filters=8)\n",
    "\n",
    "# and optimizer\n",
    "if hor:\n",
    "    adam=optimizers.Adam(lr=1e-5 * hvd.size())\n",
    "    adam=hvd.DistributedOptimizer(adam)\n",
    "else:\n",
    "    adam=optimizers.Adam(lr=1e-4)\n",
    "\n",
    "# now compile and show parameter summary\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2764, 516801, 2), (2764, 516801, 7), (2764, 516801, 2)]\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data_root='/home/magu/deepmix/data/reference_panel/'\n",
    "X = np.load(data_root+'unzipped/panel_chr20.G.npy')#, mmap_mode='r')\n",
    "Y = np.load(data_root+'unzipped/panel_chr20.L.npy')#, mmap_mode='r')\n",
    "S = np.load(data_root+'unzipped/panel_chr20.S.npy')\n",
    "print([X.shape, Y.shape, X.shape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2290\n"
     ]
    }
   ],
   "source": [
    "# and train individuals\n",
    "train=np.loadtxt('../data/reference-panel/train.strands.txt', dtype=str)\n",
    "train_ix=[i for i,q in enumerate(S) if q in train]\n",
    "np.random.shuffle(train_ix)\n",
    "print(len(train_ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and some dev individuals, why not -- first pick their indexes\n",
    "if dev:\n",
    "    n=100\n",
    "    S=np.load(data_root+'simulated/label/dev_10gen.result.npz')['S']\n",
    "    s=np.random.choice(S, size=n, replace=False)\n",
    "\n",
    "    # then load and subset -- AMR is the first ancestry label, ignored for now\n",
    "    x_f=data_root+'simulated/numpy/dev_10gen.query.ALL_X.npz'\n",
    "    y_f=data_root+'simulated/label/dev_10gen.result.npz'\n",
    "    S_f=np.load(x_f)['S']\n",
    "    X_dev=np.load(x_f)['G'][[np.where(S_f==(i))[0][0] for i in s],:nv,:na]\n",
    "    S_f=np.load(y_f)['S']\n",
    "    Y_dev=to_categorical(np.load(y_f)['L'][[np.where(S_f==(i))[0][0] for i in s],:nv], dtype='bool')[:,:,1:]\n",
    "    print([X_dev.shape, Y_dev.shape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2290/2290 [==============================] - 292s 127ms/step - loss: 1.8661 - accuracy: 0.2746\n",
      "Epoch 2/100\n",
      "2290/2290 [==============================] - 229s 100ms/step - loss: 1.7655 - accuracy: 0.3445\n",
      "Epoch 3/100\n",
      "2290/2290 [==============================] - 220s 96ms/step - loss: 1.6455 - accuracy: 0.3900\n",
      "Epoch 4/100\n",
      "2290/2290 [==============================] - 219s 96ms/step - loss: 1.4359 - accuracy: 0.4923\n",
      "Epoch 5/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 1.2678 - accuracy: 0.5748\n",
      "Epoch 6/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 1.1647 - accuracy: 0.6045\n",
      "Epoch 7/100\n",
      "2290/2290 [==============================] - 219s 96ms/step - loss: 1.0491 - accuracy: 0.6207\n",
      "Epoch 8/100\n",
      "2290/2290 [==============================] - 219s 96ms/step - loss: 0.9521 - accuracy: 0.6311\n",
      "Epoch 9/100\n",
      "2290/2290 [==============================] - 219s 95ms/step - loss: 0.8625 - accuracy: 0.6634\n",
      "Epoch 10/100\n",
      "2290/2290 [==============================] - 219s 96ms/step - loss: 0.8043 - accuracy: 0.6967\n",
      "Epoch 11/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.7540 - accuracy: 0.7121\n",
      "Epoch 12/100\n",
      "2290/2290 [==============================] - 220s 96ms/step - loss: 0.7120 - accuracy: 0.7268\n",
      "Epoch 13/100\n",
      "2290/2290 [==============================] - 219s 95ms/step - loss: 0.6767 - accuracy: 0.7346\n",
      "Epoch 14/100\n",
      "2290/2290 [==============================] - 219s 96ms/step - loss: 0.6487 - accuracy: 0.7396\n",
      "Epoch 15/100\n",
      "2290/2290 [==============================] - 220s 96ms/step - loss: 0.6013 - accuracy: 0.7462\n",
      "Epoch 16/100\n",
      "2290/2290 [==============================] - 219s 95ms/step - loss: 0.5501 - accuracy: 0.7543\n",
      "Epoch 17/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.5040 - accuracy: 0.7789\n",
      "Epoch 18/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.4359 - accuracy: 0.8167\n",
      "Epoch 19/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.3978 - accuracy: 0.8364\n",
      "Epoch 20/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.3640 - accuracy: 0.8529\n",
      "Epoch 21/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.3283 - accuracy: 0.8704\n",
      "Epoch 22/100\n",
      "2290/2290 [==============================] - 219s 96ms/step - loss: 0.3070 - accuracy: 0.8788\n",
      "Epoch 23/100\n",
      "2290/2290 [==============================] - 219s 96ms/step - loss: 0.2601 - accuracy: 0.8991\n",
      "Epoch 24/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.2490 - accuracy: 0.9048\n",
      "Epoch 25/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.2070 - accuracy: 0.9235\n",
      "Epoch 26/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.1768 - accuracy: 0.9368\n",
      "Epoch 27/100\n",
      "2290/2290 [==============================] - 219s 95ms/step - loss: 0.1629 - accuracy: 0.9422\n",
      "Epoch 28/100\n",
      "2290/2290 [==============================] - 219s 95ms/step - loss: 0.1390 - accuracy: 0.9513\n",
      "Epoch 29/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.1408 - accuracy: 0.9519\n",
      "Epoch 30/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.1185 - accuracy: 0.9601\n",
      "Epoch 31/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0969 - accuracy: 0.9679\n",
      "Epoch 32/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0906 - accuracy: 0.9698\n",
      "Epoch 33/100\n",
      "2290/2290 [==============================] - 219s 95ms/step - loss: 0.0876 - accuracy: 0.9714\n",
      "Epoch 34/100\n",
      "2290/2290 [==============================] - 219s 96ms/step - loss: 0.0765 - accuracy: 0.9741\n",
      "Epoch 35/100\n",
      "2290/2290 [==============================] - 219s 95ms/step - loss: 0.0743 - accuracy: 0.9756\n",
      "Epoch 36/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0714 - accuracy: 0.9769\n",
      "Epoch 37/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0619 - accuracy: 0.9792\n",
      "Epoch 38/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0687 - accuracy: 0.9776\n",
      "Epoch 39/100\n",
      "2290/2290 [==============================] - 219s 96ms/step - loss: 0.0540 - accuracy: 0.9822\n",
      "Epoch 40/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0515 - accuracy: 0.9830\n",
      "Epoch 41/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0528 - accuracy: 0.9830\n",
      "Epoch 42/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0554 - accuracy: 0.9823\n",
      "Epoch 43/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0429 - accuracy: 0.9855\n",
      "Epoch 44/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0436 - accuracy: 0.9852\n",
      "Epoch 45/100\n",
      "2290/2290 [==============================] - 219s 95ms/step - loss: 0.0445 - accuracy: 0.9853\n",
      "Epoch 46/100\n",
      "2290/2290 [==============================] - 219s 96ms/step - loss: 0.0460 - accuracy: 0.9857\n",
      "Epoch 47/100\n",
      "2290/2290 [==============================] - 219s 96ms/step - loss: 0.0481 - accuracy: 0.9853\n",
      "Epoch 48/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0538 - accuracy: 0.9831\n",
      "Epoch 49/100\n",
      "2290/2290 [==============================] - 220s 96ms/step - loss: 0.0325 - accuracy: 0.9893\n",
      "Epoch 50/100\n",
      "2290/2290 [==============================] - 219s 95ms/step - loss: 0.0316 - accuracy: 0.9903\n",
      "Epoch 51/100\n",
      "2290/2290 [==============================] - 219s 96ms/step - loss: 0.0370 - accuracy: 0.9883\n",
      "Epoch 52/100\n",
      "2290/2290 [==============================] - 219s 96ms/step - loss: 0.0296 - accuracy: 0.9908\n",
      "Epoch 53/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0415 - accuracy: 0.9872\n",
      "Epoch 54/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0399 - accuracy: 0.9879\n",
      "Epoch 55/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0302 - accuracy: 0.9904\n",
      "Epoch 56/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0222 - accuracy: 0.9925\n",
      "Epoch 57/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0260 - accuracy: 0.9915\n",
      "Epoch 58/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0371 - accuracy: 0.9884\n",
      "Epoch 59/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0258 - accuracy: 0.9915\n",
      "Epoch 60/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0286 - accuracy: 0.9913\n",
      "Epoch 61/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0218 - accuracy: 0.9927\n",
      "Epoch 62/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0278 - accuracy: 0.9913\n",
      "Epoch 63/100\n",
      "2290/2290 [==============================] - 219s 95ms/step - loss: 0.0352 - accuracy: 0.9894\n",
      "Epoch 64/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0244 - accuracy: 0.9925\n",
      "Epoch 65/100\n",
      "2290/2290 [==============================] - 219s 96ms/step - loss: 0.0226 - accuracy: 0.9926\n",
      "Epoch 66/100\n",
      "2290/2290 [==============================] - 219s 96ms/step - loss: 0.0179 - accuracy: 0.9936\n",
      "Epoch 67/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0251 - accuracy: 0.9921\n",
      "Epoch 68/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0275 - accuracy: 0.9918\n",
      "Epoch 69/100\n",
      "2290/2290 [==============================] - 219s 96ms/step - loss: 0.0177 - accuracy: 0.9941\n",
      "Epoch 70/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0263 - accuracy: 0.9916\n",
      "Epoch 71/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0222 - accuracy: 0.9928\n",
      "Epoch 72/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0234 - accuracy: 0.9927\n",
      "Epoch 73/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0213 - accuracy: 0.9932\n",
      "Epoch 74/100\n",
      "2290/2290 [==============================] - 219s 95ms/step - loss: 0.0182 - accuracy: 0.9941\n",
      "Epoch 75/100\n",
      "2290/2290 [==============================] - 219s 95ms/step - loss: 0.0233 - accuracy: 0.9925\n",
      "Epoch 76/100\n",
      "2290/2290 [==============================] - 219s 95ms/step - loss: 0.0186 - accuracy: 0.9939\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0221 - accuracy: 0.9928\n",
      "Epoch 78/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0166 - accuracy: 0.9946\n",
      "Epoch 79/100\n",
      "2290/2290 [==============================] - 219s 96ms/step - loss: 0.0137 - accuracy: 0.9950\n",
      "Epoch 80/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0218 - accuracy: 0.9932\n",
      "Epoch 81/100\n",
      "2290/2290 [==============================] - 219s 95ms/step - loss: 0.0125 - accuracy: 0.9954\n",
      "Epoch 82/100\n",
      "2290/2290 [==============================] - 219s 95ms/step - loss: 0.0326 - accuracy: 0.9905\n",
      "Epoch 83/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0127 - accuracy: 0.9956\n",
      "Epoch 84/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0155 - accuracy: 0.9949\n",
      "Epoch 85/100\n",
      "2290/2290 [==============================] - 220s 96ms/step - loss: 0.0208 - accuracy: 0.9936\n",
      "Epoch 86/100\n",
      "2290/2290 [==============================] - 220s 96ms/step - loss: 0.0178 - accuracy: 0.9940\n",
      "Epoch 87/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0175 - accuracy: 0.9942\n",
      "Epoch 88/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0180 - accuracy: 0.9944\n",
      "Epoch 89/100\n",
      "2290/2290 [==============================] - 219s 95ms/step - loss: 0.0140 - accuracy: 0.9955\n",
      "Epoch 90/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0173 - accuracy: 0.9945\n",
      "Epoch 91/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0104 - accuracy: 0.9961\n",
      "Epoch 92/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0137 - accuracy: 0.9953\n",
      "Epoch 93/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0170 - accuracy: 0.9948\n",
      "Epoch 94/100\n",
      "2290/2290 [==============================] - 219s 95ms/step - loss: 0.0160 - accuracy: 0.9951\n",
      "Epoch 95/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0136 - accuracy: 0.9960\n",
      "Epoch 96/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0139 - accuracy: 0.9960\n",
      "Epoch 97/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0118 - accuracy: 0.9965\n",
      "Epoch 98/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0235 - accuracy: 0.9930\n",
      "Epoch 99/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0135 - accuracy: 0.9960\n",
      "Epoch 100/100\n",
      "2290/2290 [==============================] - 218s 95ms/step - loss: 0.0143 - accuracy: 0.9959\n"
     ]
    }
   ],
   "source": [
    "# now try it out!\n",
    "if dev: # dev assumes oce\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25) # not implemented below\n",
    "\n",
    "    # fit with generator, or not\n",
    "    if gen:\n",
    "        params={'X':X, 'Y':Y, 'dim':nv, 'batch_size':32, 'n_classes':nc, 'n_alleles':na}\n",
    "        generator=DataGenerator(train_ix, **params)\n",
    "        history=model.fit_generator(generator=generator, epochs=ne, validation_data=(X_dev, Y_dev), callbacks=[es])\n",
    "    else:\n",
    "        history=model.fit(X[train_ix,:nv,:na], Y[train_ix,:nv,:], batch_size=4, epochs=ne, callbacks=[es])\n",
    "elif not oce:\n",
    "    train_ixx=[i for i in train_ix if Y[i,0,:].dot(np.arange(nc))!=4]\n",
    "    history=model.fit(X[train_ixx,:nv,:na], Y[train_ixx,:nv,:][:,:,[i for i in range(nc) if i!=4]], \n",
    "                      batch_size=4, epochs=ne)\n",
    "else:\n",
    "    history=model.fit(X[train_ix,:nv,:na], Y[train_ix,:nv,:], batch_size=4, epochs=ne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "model.save('chm21_short.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, dev_acc = model.evaluate(X_dev, Y_dev, verbose=0)\n",
    "\n",
    "# 1.1) plot loss during training\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(1, (9,9))\n",
    "plt.subplot(211)\n",
    "plt.title('Loss during training')\n",
    "plt.plot(history.history['loss'], label='train set')\n",
    "plt.plot(history.history['val_loss'], label='dev set')\n",
    "plt.legend()\n",
    "\n",
    "# 1.2) plot accuracy during training\n",
    "plt.subplot(212)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['accuracy'], label='train set')\n",
    "plt.plot(history.history['val_accuracy'], label='dev set')\n",
    "plt.legend()\n",
    "\n",
    "print(dev_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_p=model.predict(X_dev)\n",
    "Y_hat=np.argmax(Y_hat_p, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(Y_hat.shape[0]):\n",
    "    print((i, [np.count_nonzero(Y_hat[i,:]==j) for j in range(Y_hat_p.shape[-1])], \n",
    "           [np.count_nonzero(Y_dev[i,:,:].argmax(axis=-1)==j) for j in range(Y_hat_p.shape[-1])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "Y_dev_lab = np.argmax(Y_dev, axis=-1)\n",
    "plt.subplot(211)\n",
    "plt.title('Dev set ground truths')\n",
    "plt.imshow(Y_dev_lab[48:49,:].astype(int), aspect='auto')#, cmap='jet')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title('Corresponding dev set predictions')\n",
    "plt.imshow(Y_hat[48:49,:].astype(int), aspect='auto')#, cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.argmax(Y_hat_p[48,:,:], axis=-1)==3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "Y_dev_lab = np.argmax(Y_dev, axis=-1)\n",
    "plt.subplot(211)\n",
    "plt.title('Dev set ground truths')\n",
    "plt.imshow(Y_dev_lab[48:49,29000:29500].astype(int), aspect='auto')#, cmap='jet')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title('Corresponding dev set predictions')\n",
    "plt.imshow(Y_hat[48:49,29000:29500].astype(int), aspect='auto')#, cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Y_hat_p[48,np.where(np.argmax(Y_hat_p[48,:,:], axis=-1)==3),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seems like a crf-smoother (even a post-hoc one) could really help"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
